provider: autogen_ext.models.openai.OpenAIChatCompletionClient
config:
  model: model-sql
  base_url: http://litellm:4000/v1/
  temperature: 0
  cache_seed: 42
  model_info:
    vision: false
    function_calling: true
    json_output: true
    family: openai